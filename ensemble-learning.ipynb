{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "employed-contribution",
   "metadata": {
    "papermill": {
     "duration": 0.01459,
     "end_time": "2021-05-25T06:57:31.123088",
     "exception": false,
     "start_time": "2021-05-25T06:57:31.108498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## What is ensemble learning ?\n",
    "\n",
    "In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooperative-commercial",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:31.156869Z",
     "iopub.status.busy": "2021-05-25T06:57:31.155104Z",
     "iopub.status.idle": "2021-05-25T06:57:31.157602Z",
     "shell.execute_reply": "2021-05-25T06:57:31.158103Z",
     "shell.execute_reply.started": "2021-05-25T06:57:14.227447Z"
    },
    "papermill": {
     "duration": 0.021692,
     "end_time": "2021-05-25T06:57:31.158390",
     "exception": false,
     "start_time": "2021-05-25T06:57:31.136698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "multiple-spine",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:31.192537Z",
     "iopub.status.busy": "2021-05-25T06:57:31.191807Z",
     "iopub.status.idle": "2021-05-25T06:57:36.452164Z",
     "shell.execute_reply": "2021-05-25T06:57:36.451580Z",
     "shell.execute_reply.started": "2021-05-25T06:57:14.235852Z"
    },
    "papermill": {
     "duration": 5.280403,
     "end_time": "2021-05-25T06:57:36.452370",
     "exception": false,
     "start_time": "2021-05-25T06:57:31.171967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0d0f9a38decb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cudf'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import math\n",
    "import random \n",
    "import os \n",
    "import cv2\n",
    "import timm\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import albumentations as A \n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import Dataset \n",
    "from torch import nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "import gc\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ranging-accountability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.489229Z",
     "iopub.status.busy": "2021-05-25T06:57:36.488223Z",
     "iopub.status.idle": "2021-05-25T06:57:36.491354Z",
     "shell.execute_reply": "2021-05-25T06:57:36.490839Z"
    },
    "papermill": {
     "duration": 0.024704,
     "end_time": "2021-05-25T06:57:36.491497",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.466793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    \n",
    "    img_size = 512\n",
    "    fc_dim = 512\n",
    "    batch_size = 12\n",
    "    seed = 2001\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    classes = 11014\n",
    "    \n",
    "    model_name = 'tf_efficientnet_b5_ns'\n",
    "    model_name1 =  'tf_efficientnet_b4'\n",
    "    model_name2 = 'eca_nfnet_l0'\n",
    "    \n",
    "    model_path = '../input/shopee-pytorch-models/arcface_512x512_eff_b5_.pt'\n",
    "    model_path1 = '../input/utils-shopee/arcface_512x512_tf_efficientnet_b4_LR.pt'\n",
    "    model_path2 = '../input/shopee-pytorch-models/arcface_512x512_nfnet_l0 (mish).pt'\n",
    "    \n",
    "    scale = 30 \n",
    "    margin = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "valued-president",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.528514Z",
     "iopub.status.busy": "2021-05-25T06:57:36.527697Z",
     "iopub.status.idle": "2021-05-25T06:57:36.534105Z",
     "shell.execute_reply": "2021-05-25T06:57:36.533408Z"
    },
    "papermill": {
     "duration": 0.028425,
     "end_time": "2021-05-25T06:57:36.534250",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.505825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "    df_cu = cudf.DataFrame(df)\n",
    "    image_paths = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "    return df, df_cu, image_paths\n",
    "\n",
    "def seed_torch(seed=45):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(CFG.seed)\n",
    "\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
    "    return ' '.join( np.unique(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "drawn-female",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.577536Z",
     "iopub.status.busy": "2021-05-25T06:57:36.571627Z",
     "iopub.status.idle": "2021-05-25T06:57:36.581240Z",
     "shell.execute_reply": "2021-05-25T06:57:36.580671Z"
    },
    "papermill": {
     "duration": 0.032668,
     "end_time": "2021-05-25T06:57:36.581380",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.548712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_predictions(df, embeddings1, embeddings2, embeddings3, threshold = 3.4):\n",
    "    \n",
    "    if len(df) > 3:\n",
    "        KNN = 50\n",
    "    else : \n",
    "        KNN = 3\n",
    "    \n",
    "    #--\n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings1)\n",
    "    distances, indices = model.kneighbors(embeddings1)\n",
    "    \n",
    "    threshold = 1.69\n",
    "    predictions1 = []\n",
    "    for k in tqdm(range(embeddings1.shape[0])):\n",
    "        idx = np.where(distances[k,] < threshold)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = list(df['posting_id'].iloc[ids])\n",
    "        predictions1.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices, embeddings1\n",
    "    gc.collect()\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN)\n",
    "    model.fit(embeddings2)\n",
    "    distances, indices = model.kneighbors(embeddings2)\n",
    "    \n",
    "    threshold = 4.39\n",
    "    predictions2 = []\n",
    "    for k in tqdm(range(embeddings2.shape[0])):\n",
    "        idx = np.where(distances[k,] < threshold)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = list(df['posting_id'].iloc[ids])\n",
    "        predictions2.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices, embeddings2\n",
    "    gc.collect()\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\n",
    "    model.fit(embeddings3)\n",
    "    distances, indices = model.kneighbors(embeddings3)\n",
    "    \n",
    "    threshold=0.37\n",
    "    predictions3 = []\n",
    "    for k in tqdm(range(embeddings3.shape[0])):\n",
    "        idx = np.where(distances[k,] < threshold)[0]\n",
    "        ids = indices[k,idx]\n",
    "        posting_ids = list(df['posting_id'].iloc[ids])\n",
    "        predictions3.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices, embeddings3\n",
    "    gc.collect()\n",
    "    \n",
    "    predictions = [list(set(a + c)) for a, b, c in zip(predictions1, predictions2, predictions3)]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "boring-radiation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.615586Z",
     "iopub.status.busy": "2021-05-25T06:57:36.614596Z",
     "iopub.status.idle": "2021-05-25T06:57:36.617400Z",
     "shell.execute_reply": "2021-05-25T06:57:36.617913Z"
    },
    "papermill": {
     "duration": 0.022409,
     "end_time": "2021-05-25T06:57:36.618080",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.595671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_transforms():\n",
    "\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(CFG.img_size,CFG.img_size,always_apply=True),\n",
    "            A.Normalize(),\n",
    "        ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rural-boating",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.655107Z",
     "iopub.status.busy": "2021-05-25T06:57:36.654433Z",
     "iopub.status.idle": "2021-05-25T06:57:36.658115Z",
     "shell.execute_reply": "2021-05-25T06:57:36.657599Z"
    },
    "papermill": {
     "duration": 0.024719,
     "end_time": "2021-05-25T06:57:36.658263",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.633544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.augmentations = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.image_paths.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented['image']       \n",
    "    \n",
    "        return image,torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brief-break",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.734064Z",
     "iopub.status.busy": "2021-05-25T06:57:36.721524Z",
     "iopub.status.idle": "2021-05-25T06:57:36.737012Z",
     "shell.execute_reply": "2021-05-25T06:57:36.736349Z",
     "shell.execute_reply.started": "2021-05-25T06:57:14.370658Z"
    },
    "papermill": {
     "duration": 0.064545,
     "end_time": "2021-05-25T06:57:36.737161",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.672616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.49, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "            \n",
    "        one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        #one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output\n",
    "    \n",
    "class ShopeeModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes,\n",
    "        model_name = CFG.model_name,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = False,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "            \n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'nfnet_f3':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "\n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "        \n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ShopeeModel1(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes,\n",
    "        model_name = CFG.model_name1,\n",
    "        fc_dim = CFG.fc_dim,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = True):\n",
    "\n",
    "        super(ShopeeModel1, self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        in_features = self.backbone.classifier.in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=0.1)\n",
    "            self.classifier = nn.Linear(in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            in_features = fc_dim\n",
    "            \n",
    "        self.final = ArcMarginProduct(\n",
    "            in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.constant_(self.classifier.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        features = self.extract_features(image)\n",
    "        if self.training:\n",
    "            logits = self.final(features, label)\n",
    "            return logits\n",
    "        else:\n",
    "            return features\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "        \n",
    "        if self.use_fc and self.training:\n",
    "            x = self.dropout(x)\n",
    "            x = self.classifier(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ShopeeModel2(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.classes,\n",
    "        model_name = CFG.model_name2,\n",
    "        fc_dim = 512,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = False):\n",
    "\n",
    "\n",
    "        super(ShopeeModel2,self).__init__()\n",
    "        print('Building Model Backbone for {} model'.format(model_name))\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if model_name == 'resnext50_32x4d':\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "            \n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif model_name == 'tf_efficientnet_b5_ns':\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif model_name == 'eca_nfnet_l0':\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.0)\n",
    "        self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "        self.bn = nn.BatchNorm1d(fc_dim)\n",
    "        self._init_params()\n",
    "        final_in_features = fc_dim\n",
    "        \n",
    "        self.final = ArcMarginProduct(\n",
    "            final_in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        #logits = self.final(feature,label)\n",
    "        return feature\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "        \n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "looking-sherman",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.778028Z",
     "iopub.status.busy": "2021-05-25T06:57:36.776948Z",
     "iopub.status.idle": "2021-05-25T06:57:36.780155Z",
     "shell.execute_reply": "2021-05-25T06:57:36.779639Z"
    },
    "papermill": {
     "duration": 0.028855,
     "end_time": "2021-05-25T06:57:36.780328",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.751473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mish_func(torch.autograd.Function):\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i * torch.tanh(F.softplus(i))\n",
    "        ctx.save_for_backward(i)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        i = ctx.saved_variables[0]\n",
    "  \n",
    "        v = 1. + i.exp()\n",
    "        h = v.log() \n",
    "        grad_gh = 1./h.cosh().pow_(2) \n",
    "\n",
    "        grad_hx = i.sigmoid()\n",
    "\n",
    "        grad_gx = grad_gh *  grad_hx\n",
    "        \n",
    "        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n",
    "        \n",
    "        return grad_output * grad_f \n",
    "\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    def forward(self, input_tensor):\n",
    "        return Mish_func.apply(input_tensor)\n",
    "    \n",
    "def replace_activations(model, existing_layer, new_layer):\n",
    "    \n",
    "    \n",
    "    for name, module in reversed(model._modules.items()):\n",
    "        if len(list(module.children())) > 0:\n",
    "            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n",
    "\n",
    "        if type(module) == existing_layer:\n",
    "            layer_old = module\n",
    "            layer_new = new_layer\n",
    "            model._modules[name] = layer_new\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vital-triumph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.828320Z",
     "iopub.status.busy": "2021-05-25T06:57:36.827248Z",
     "iopub.status.idle": "2021-05-25T06:57:36.830319Z",
     "shell.execute_reply": "2021-05-25T06:57:36.829730Z"
    },
    "papermill": {
     "duration": 0.035833,
     "end_time": "2021-05-25T06:57:36.830469",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.794636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings(image_paths, model_name = CFG.model_name):\n",
    "    embeds = []\n",
    "    \n",
    "    model = ShopeeModel(model_name = model_name)\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(CFG.model_path))\n",
    "    model = model.to(CFG.device)\n",
    "\n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "            \n",
    "    del model, image_embeddings\n",
    "    image_embeddings1 = np.concatenate(embeds)\n",
    "    print(f'image embeddings1 shape is {image_embeddings1.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    \n",
    "    #---\n",
    "    model = ShopeeModel1(pretrained=False).to(CFG.device)\n",
    "    model.load_state_dict(torch.load(CFG.model_path1))\n",
    "    model.eval()\n",
    "\n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths, transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    embeds1 = []\n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            features = model(img,label)\n",
    "            image_embeddings = features.detach().cpu().numpy()\n",
    "            embeds1.append(image_embeddings)\n",
    "            \n",
    "    del model, image_embeddings\n",
    "    image_embeddings2 = np.concatenate(embeds1)\n",
    "    print(f'image embeddings2 shape is {image_embeddings2.shape}')\n",
    "    del embeds1\n",
    "    gc.collect()\n",
    "    #---\n",
    "    \n",
    "    model = ShopeeModel2()\n",
    "    model.eval()\n",
    "    model = replace_activations(model, torch.nn.SiLU, Mish())\n",
    "\n",
    "    model.load_state_dict(torch.load(CFG.model_path2))\n",
    "    model = model.to(CFG.device)\n",
    "    \n",
    "    image_dataset = ShopeeDataset(image_paths=image_paths,transforms=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    embeds2 = []\n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.cuda()\n",
    "            label = label.cuda()\n",
    "            feat = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds2.append(image_embeddings)\n",
    "    \n",
    "    del model\n",
    "    image_embeddings3 = np.concatenate(embeds2)\n",
    "    print(f'image embeddings3 shape is {image_embeddings3.shape}')\n",
    "    del embeds2\n",
    "    gc.collect()\n",
    "    \n",
    "    return image_embeddings1, image_embeddings2, image_embeddings3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "received-midnight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.868481Z",
     "iopub.status.busy": "2021-05-25T06:57:36.867747Z",
     "iopub.status.idle": "2021-05-25T06:57:36.871320Z",
     "shell.execute_reply": "2021-05-25T06:57:36.870797Z"
    },
    "papermill": {
     "duration": 0.026487,
     "end_time": "2021-05-25T06:57:36.871467",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.844980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_predictions(df, max_features = 25000):\n",
    "    \n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "    preds = []\n",
    "    CHUNK = 1024*4\n",
    "\n",
    "    CTS = len(df)//CHUNK\n",
    "    if len(df)%CHUNK!=0: CTS += 1\n",
    "    for j in range( CTS ):\n",
    "\n",
    "        a = j*CHUNK\n",
    "        b = (j+1)*CHUNK\n",
    "        b = min(b,len(df))\n",
    "\n",
    "        cts = cupy.matmul( text_embeddings, text_embeddings[a:b].T).T\n",
    "\n",
    "        for k in range(b-a):\n",
    "            IDX = cupy.where(cts[k,]>0.74)[0]\n",
    "            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "            preds.append(o)\n",
    "    \n",
    "    del model,text_embeddings\n",
    "    gc.collect()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "healthy-cabin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:36.905817Z",
     "iopub.status.busy": "2021-05-25T06:57:36.905146Z",
     "iopub.status.idle": "2021-05-25T06:57:36.950059Z",
     "shell.execute_reply": "2021-05-25T06:57:36.949462Z"
    },
    "papermill": {
     "duration": 0.064217,
     "end_time": "2021-05-25T06:57:36.950221",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.886004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cudf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-721b91470011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_cu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-9e77dadc3956>\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/shopee-product-matching/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf_cu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/shopee-product-matching/test_images/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_cu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cudf' is not defined"
     ]
    }
   ],
   "source": [
    "df,df_cu,image_paths = read_dataset()\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "clinical-latex",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:37.001355Z",
     "iopub.status.busy": "2021-05-25T06:57:37.000190Z",
     "iopub.status.idle": "2021-05-25T06:57:37.005151Z",
     "shell.execute_reply": "2021-05-25T06:57:37.004512Z"
    },
    "papermill": {
     "duration": 0.039909,
     "end_time": "2021-05-25T06:57:37.005296",
     "exception": false,
     "start_time": "2021-05-25T06:57:36.965387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-35f4b0975332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_embeddings1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embeddings2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embeddings3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimage_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embeddings1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embeddings2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_embeddings3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.69\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_text_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_paths' is not defined"
     ]
    }
   ],
   "source": [
    "image_embeddings1, image_embeddings2, image_embeddings3 = get_image_embeddings(image_paths.values)\n",
    "image_predictions = get_image_predictions(df, image_embeddings1, image_embeddings2, image_embeddings3, threshold = 1.69)\n",
    "text_predictions = get_text_predictions(df, max_features = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hispanic-begin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T06:57:37.052471Z",
     "iopub.status.busy": "2021-05-25T06:57:37.047241Z",
     "iopub.status.idle": "2021-05-25T06:57:37.060632Z",
     "shell.execute_reply": "2021-05-25T06:57:37.060050Z"
    },
    "papermill": {
     "duration": 0.040182,
     "end_time": "2021-05-25T06:57:37.060776",
     "exception": false,
     "start_time": "2021-05-25T06:57:37.020594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5d1f542fe688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'posting_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'matches'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#df[['posting_id', 'matches']].head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "df['image_predictions'] = image_predictions\n",
    "df['text_predictions'] = text_predictions\n",
    "df['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "#df[['posting_id', 'matches']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-senior",
   "metadata": {
    "papermill": {
     "duration": 0.015231,
     "end_time": "2021-05-25T06:57:37.091583",
     "exception": false,
     "start_time": "2021-05-25T06:57:37.076352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### P.S. :- Just experimented with some weights and values, got an imbalance at the end, do try your own modifications and try to come with better results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12.920826,
   "end_time": "2021-05-25T06:57:38.017381",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-25T06:57:25.096555",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
